{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3373f2c7-da8e-49eb-8300-25ae4a00fdaa",
   "metadata": {},
   "source": [
    "# Welcome to lumigator foxfooding!\n",
    "\n",
    "## Agenda\n",
    "\n",
    "+ Introduction and setup environment (credentials)\n",
    "+ Platform Setup and Walkthrough\n",
    "+ Explanation of and Examination of Thunderbird Ground Truth\n",
    "+ Model Selection ( 1 encoder/decoder), (2 decoder), eval against GPT4\n",
    "+ Run experiment and show results\n",
    "+ Evaluate results and discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f309f-5074-4fca-8fc7-974c4e35bee4",
   "metadata": {},
   "source": [
    "## Foxfooding Introduction and Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b47fb-996a-4931-921f-4027e5930c83",
   "metadata": {},
   "source": [
    "## Who we are, what we do, about the platform, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee9839-3102-47e4-8bb5-0cbd8c68f537",
   "metadata": {},
   "source": [
    "## Platform Setup and Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8237ee62-33d1-480d-864f-03f70537c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import lumigator_demo as ld\n",
    "\n",
    "from datasets import load_dataset\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18c813-36f8-4439-880d-441499e80493",
   "metadata": {},
   "source": [
    "Write your team name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67092b57-e4ff-4fd7-a46b-f6ab9c56c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"lumigator_enthusiasts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e914253-e217-42f8-85a2-59f32daf6779",
   "metadata": {},
   "source": [
    "## Working with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd66191-c874-4303-bd26-ef93388a124f",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "The following dataset is already in the format that we need as input: \n",
    "- one field called `examples` containing the text to summarize\n",
    "- one field called `ground_truth` containing the summaries to the models' outputs against\n",
    "\n",
    "Note that you can load many different types of file formats in a similar way (see https://huggingface.co/docs/datasets/loading#local-and-remote-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1260eae7-f978-46ba-9994-da5734a02319",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"thunderbird.csv\"\n",
    "\n",
    "### commented until the dataset is final - just use the following cell to download the dataset\n",
    "# ds = load_dataset(\"csv\", data_files = dataset_name, split=\"train\")\n",
    "# ds = ds.to_pandas()\n",
    "\n",
    "# show / do things with the dataset here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0682d-0dd6-49b1-a4dc-8581760b1a59",
   "metadata": {},
   "source": [
    "## Dataset Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63fbcb60-5940-41e5-873f-b346f8bad5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = ld.dataset_upload(dataset_name)\n",
    "# dataset_id = ld.get_resource_id(r)\n",
    "\n",
    "dataset_id = \"95802e81-0334-476c-9b08-aa5da07fde9f\" # thunderbird pre-saved dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4008d0-cdc3-403e-a46e-88cca708d91e",
   "metadata": {},
   "source": [
    "### Check dataset info\n",
    "\n",
    "At any point, one can get dataset info by just providing its UUID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba59f93-d5ac-416e-8ff4-79db147627c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"95802e81-0334-476c-9b08-aa5da07fde9f\",\n",
      "  \"filename\": \"thunderbird.csv\",\n",
      "  \"format\": \"experiment\",\n",
      "  \"size\": 151137,\n",
      "  \"created_at\": \"2024-07-26T15:39:40.700918Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = ld.dataset_info(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2876b7f8-e645-4791-aa27-351e3296e2de",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "What you see below are different lists of models we have already tested for the summarization task.\n",
    "The `models` variable at the end provides you with a selection, but you can choose any combination of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fcdf76-c9ad-4459-b0c3-49098286ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_models = [\n",
    "    'hf://facebook/bart-large-cnn',\n",
    "    'hf://mikeadimech/longformer-qmsum-meeting-summarization', \n",
    "    'hf://mrm8488/t5-base-finetuned-summarize-news',\n",
    "    'hf://Falconsai/text_summarization',\n",
    "]\n",
    "\n",
    "dec_models = [\n",
    "    'hf://mistralai/Mistral-7B-Instruct-v0.3',\n",
    "    # TODO: test more dec_models such as\n",
    "    # 'hf://meta-llama/Meta-Llama-3-8B',\n",
    "    # 'hf://microsoft/Phi-3-mini-4k-instruct',\n",
    "]\n",
    "\n",
    "gpts = [\n",
    "    \"oai://gpt-4o-mini\",\n",
    "    \"oai://gpt-4-turbo\",\n",
    "    \"oai://gpt-3.5-turbo-0125\"  \n",
    "]\n",
    "\n",
    "models = [\n",
    "    enc_dec_models[0],\n",
    "    dec_models[0],\n",
    "    gpts[1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1af4e7-5a02-4e5a-b2f5-a065716ddbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hf://facebook/bart-large-cnn',\n",
       " 'hf://mistralai/Mistral-7B-Instruct-v0.3',\n",
       " 'oai://gpt-4-turbo']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74658955-4a41-4be1-b29d-8efa734bed9d",
   "metadata": {},
   "source": [
    "## Run Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b73f6a1-7be9-43a7-8304-4cb6a408318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"5a2a95c4-9902-4841-81ab-c9818a9a86a2\",\n",
      "  \"name\": \"lumigator_enthusiasts\",\n",
      "  \"description\": \"Testing hf://facebook/bart-large-cnn summarization model on thunderbird.csv\",\n",
      "  \"status\": \"created\",\n",
      "  \"created_at\": \"2024-07-26T17:12:14.978142Z\",\n",
      "  \"updated_at\": null\n",
      "}\n",
      "{\n",
      "  \"id\": \"218cc213-6e5d-4b86-821b-727bc4527b35\",\n",
      "  \"name\": \"lumigator_enthusiasts\",\n",
      "  \"description\": \"Testing hf://mistralai/Mistral-7B-Instruct-v0.3 summarization model on thunderbird.csv\",\n",
      "  \"status\": \"created\",\n",
      "  \"created_at\": \"2024-07-26T17:12:15.730906Z\",\n",
      "  \"updated_at\": null\n",
      "}\n",
      "{\n",
      "  \"id\": \"ece1e25a-9f53-42cf-838b-984d58f07f91\",\n",
      "  \"name\": \"lumigator_enthusiasts\",\n",
      "  \"description\": \"Testing oai://gpt-4-turbo summarization model on thunderbird.csv\",\n",
      "  \"status\": \"created\",\n",
      "  \"created_at\": \"2024-07-26T17:12:16.449763Z\",\n",
      "  \"updated_at\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# change the following to 0 to use all samples in the dataset\n",
    "max_samples = 10\n",
    "\n",
    "responses = []\n",
    "for model in models:\n",
    "    descr = f\"Testing {model} summarization model on {dataset_name}\"\n",
    "    responses.append(ld.experiments_submit(model, team_name, descr, dataset_id, max_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f787190-4581-4c26-beca-0260303a68bd",
   "metadata": {},
   "source": [
    "### Track evaluation jobs\n",
    "\n",
    "Run the following to track your evaluation jobs.\n",
    "\n",
    "- *NOTE*: you won't be able to run other cells while this one is running. However, you can interrupt it whenever you want by clicking on the \"stop\" button above and run it at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2858bcea-6fcb-4441-b56e-5d89502f10e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a2a95c4-9902-4841-81ab-c9818a9a86a2: SUCCEEDED\n",
      "218cc213-6e5d-4b86-821b-727bc4527b35: SUCCEEDED\n",
      "ece1e25a-9f53-42cf-838b-984d58f07f91: SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "job_ids = [ld.get_resource_id(r) for r in responses]\n",
    "\n",
    "wip = ld.show_experiment_statuses(job_ids)\n",
    "while wip == True:\n",
    "    time.sleep(5)\n",
    "    clear_output()\n",
    "    wip=ld.show_experiment_statuses(job_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8cbf3-e44f-4f1e-b520-3f6fac147fca",
   "metadata": {},
   "source": [
    "## Show evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8709b8-59ba-4a9c-81bd-59b2fc612f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after the jobs complete, gather evaluation results\n",
    "eval_results = []\n",
    "for job_id in job_ids:\n",
    "    eval_results.append(ld.experiments_result_download(job_id))\n",
    "\n",
    "# convert results into a pandas dataframe\n",
    "eval_table = ld.eval_results_to_table(models, eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10cf5e90-7fa2-4a7d-98bf-2ff5d736c05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>BERT Precision</th>\n",
       "      <th>BERT Recall</th>\n",
       "      <th>BERT F1</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook/bart-large-cnn</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>0.446223</td>\n",
       "      <td>0.808785</td>\n",
       "      <td>0.938535</td>\n",
       "      <td>0.868610</td>\n",
       "      <td>0.250750</td>\n",
       "      <td>0.238054</td>\n",
       "      <td>0.238879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.316353</td>\n",
       "      <td>0.859208</td>\n",
       "      <td>0.882404</td>\n",
       "      <td>0.870604</td>\n",
       "      <td>0.328549</td>\n",
       "      <td>0.105376</td>\n",
       "      <td>0.214223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model    Meteor  BERT Precision  BERT Recall  \\\n",
       "0             facebook/bart-large-cnn  0.999994        1.000000     1.000000   \n",
       "1  mistralai/Mistral-7B-Instruct-v0.3  0.446223        0.808785     0.938535   \n",
       "2                         gpt-4-turbo  0.316353        0.859208     0.882404   \n",
       "\n",
       "    BERT F1   ROUGE-1   ROUGE-2   ROUGE-L  \n",
       "0  1.000000  1.000000  1.000000  1.000000  \n",
       "1  0.868610  0.250750  0.238054  0.238879  \n",
       "2  0.870604  0.328549  0.105376  0.214223  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbdaec-a1e9-4731-bfdd-b471e6a0fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e9aff3-5d33-4cd0-a7f4-8cb0811155b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
