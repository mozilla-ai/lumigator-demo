{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3373f2c7-da8e-49eb-8300-25ae4a00fdaa",
   "metadata": {},
   "source": [
    "# Welcome to Lumigator Foxfooding from [Mozilla.ai](https://www.mozilla.ai/)! üêä ü¶ä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe362e97",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "+ Working with Jupyter Notebooks\n",
    "+ Lumigator Platform Overview  üêä\n",
    "+ Understanding Machine Learning Workflows \n",
    "+ Thunderbird Dataset Walkthrough\n",
    "+ Explanation of and Examination of Thunderbird Ground Truth\n",
    "+ Model Selection ( 1 encoder/decoder), (2 decoder), eval against GPT4\n",
    "+ Run experiment and show results\n",
    "+ Evaluate results and discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e41dab1",
   "metadata": {},
   "source": [
    "## Jupyter Walkthrough\n",
    "\n",
    "[Jupyter Notebooks](https://jupyter-notebook.readthedocs.io/en/stable/) are an executable code/text environment for (usually) Python code. Our Jupyter environment is in JupyterHub. To work with Jupyter, click \"run cell\" to run the code and see results below the cell you're currently running. Cells are executed sequentially. \n",
    "\n",
    "In some cells, you will see cases where there are variables that you'll need to pre-populate before running the cell. They look like this. The code will not work unless you replace it!  \n",
    "\n",
    "```python\n",
    "# suggestion: \"lumigator_enthusiasts\"\n",
    "team_name = TEAM_NAME_HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bfb102",
   "metadata": {},
   "source": [
    "# Running cells \n",
    "To run a cell, press the \"play\" icon in the top bar. If a cell is taking too long, you can press stop. \n",
    "\n",
    "\n",
    "<img src=\"running.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Your files are located on the left-hand side. They'll be saved for the duration of our session, but if you'd like to keep them, make sure to download them. \n",
    "\n",
    "<img src=\"files.png\" alt=\"drawing\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26c697c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Lumigator!üêä\n"
     ]
    }
   ],
   "source": [
    "## Lets' try running some code!\n",
    "\n",
    "print(\"Welcome to Lumigator!üêä\")\n",
    "\n",
    "# You can see the output below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81137051",
   "metadata": {},
   "source": [
    "For more on notebooks and how cell works, check out this demo. [You can click links in cells.](https://github.com/nbgallery/Jupyter4Analysts/blob/main/J4A%20Notebook%201%20-%20Jupyter%20Syntax%20and%20Other%20Things.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecaa846",
   "metadata": {},
   "source": [
    "## Glossary of terms \n",
    "\n",
    "Some terms you'll hear us using throughout the session: \n",
    "\n",
    "+ **Machine learning** - The process of creating a model that learns from data\n",
    "+ **Dataset** - Data used to train models\n",
    "+ **LLM** - Large language model, [a text-based model that performs next-word predictions](https://www.nvidia.com/en-us/glossary/large-language-models/) \n",
    "+ **Tokens** - Words broken up into pieces to be used in an LLM \n",
    "+ **Inference** - The process of getting a prediction from a large language model \n",
    "+ **Embeddings** - Numerical representations of text generated by modeling \n",
    "+ **Encoder-decoder models** - a neural network architecture comprised of two neural networks, an encoder that takes the input vectors from our data and creates an embedding of a fixed length, and a decoder, also a neural network, which takes the embeddings encoded as input and generates a static set of outputs such as translated text or a text summary\n",
    "+ **Decoder-only models** - Receive a prompt of text directly and predict the next word\n",
    "+ **Task** - Machine learning tasks to fit a specific model type, including translation, summarization, completion, etc. \n",
    "+ **Ground truth** - A dataset that has been evaluated to be true by humans (or LLMs, in some cases) to be correct, that we can use as a point of comparison for our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfaf888",
   "metadata": {},
   "source": [
    "# Machine Learning Workflows\n",
    "\n",
    "In machine learning, we are looking to generate a model artifact from data. We have several stages we care about: the data preprocessing, model training, model generation, inference, and evaluation. \n",
    "\n",
    "<img src=\"ml_workflow.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Within the universe of modeling approaches, there are supervised and unsupervised approaches, as well as reinforcement learning. When we think of language modeling, that falls in the realm of neural network approaches. \n",
    "\n",
    "\n",
    "<img src=\"ml_family.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "\n",
    "Lumigator focuses on **inference** and **evaluation** for large language models: we want to be able to take our own dataset, perform inference on it, and evaluate the results to see if the model we would like to use produces good results for our use-cases. Use-cases include cases that are specific to our business. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8139990",
   "metadata": {},
   "source": [
    "In order to select an LLM, we need the following stages: \n",
    "\n",
    "1. Generate ground truth for our business use-case\n",
    "2. Pick several models we'd like to use to evaluate\n",
    "3. Run an evaluation loop consisting of looking at the ground truth in comparison to model results\n",
    "4. Analyze our evaluations. \n",
    "\n",
    "These are the steps that Lumigator completes. Here's a platform overview\n",
    "\n",
    "\n",
    "<img src=\"platform.png\" alt=\"drawing\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d2fd4",
   "metadata": {},
   "source": [
    "## Machine learning is alchemy\n",
    "\n",
    "When we think of traditional software application workflows, we think of an example such as adding a button. We can clearly test that we've added a blue button to our application, and that it works correctly. Machine learning is not like this! It involves a lot of experimentation, tweaking of hyperparameters and prompts and trying different models. Expect for the process to be imperfect, with many iterative loops. Luckily, Lumigator helps take away the uncertainty of at least model selection :)\n",
    "\n",
    "> There‚Äôs a self-congratulatory feeling in the air. We say things like ‚Äúmachine learning is the new electricity‚Äù. I‚Äôd like to offer an alternative metaphor: machine learning has become alchemy. - [Ben Recht and Ali Rahimi](https://archives.argmin.net/2017/12/05/kitchen-sinks/)\n",
    "\n",
    "Ultimately, the final conclusion of whether a model is good is if humans think it's good. \n",
    "\n",
    "With that in mind, let's dive into setting up experiments with Lumigator to test our models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bbdf25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a library of utility functions that will help us connect to the Lumigator API\n",
    "# Let's take a second to walk through them \n",
    "\n",
    "import lumigator_demo as ld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8237ee62-33d1-480d-864f-03f70537c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages we need to work with data \n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# wrap columns for inspection\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "# stylesheet for visibility\n",
    "plt.style.use(\"fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a852789a",
   "metadata": {},
   "source": [
    "# Understanding the Lumigator App and API \n",
    "\n",
    " The app itself consists of an API, which you can access and test out methods with in the [OpenAPI spec](https://swagger.io/specification/), at the platform URL, under docs. \n",
    "\n",
    "<img src=\"openapi.png\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "[Here](https://lumigator.mzai.dev/docs) are the docs for the Lumigator API. In looking at them, we can see that we have 7 endpoints. \n",
    "The application is split up into `jobs`, `deployments`, `datasets`, `experiments`, and `completions`.\n",
    "\n",
    "+ `Datasets` - Data that we add to the platform for evaluation. We can upload, delete, and save different data in the platform. \n",
    "+ `Experiments` - a tag that we create to associate all of our data\n",
    "+ `Jobs` - Check running status of lm-buddy evaluation jobs\n",
    "+ `Deployments` - Running Ray-serve deployments with locally-hosted models\n",
    "+ `Completions` - Access to external APIs such as Mistral and OpenAI\n",
    "+ `Health` - Status of the application, jobs and deployments. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18c813-36f8-4439-880d-441499e80493",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "Let's start by creating a team name for our experiments to organize our data, pick a team name below and run the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67092b57-e4ff-4fd7-a46b-f6ab9c56c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggestion: \"lumigator_enthusiasts\"\n",
    "team_name = TEAM_NAME_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961f5ff",
   "metadata": {},
   "source": [
    "## Model Task\n",
    "\n",
    "The task we'll be working with is summarization, aka we want to generate a summary of our text. In this particular case, emails. Finding a good model for summarization is a daunting task, as the typical intuition that larger parameter models generally perform better goes out the window. For summarization, we need to consider the input, which will likely be of a longer context size, and finding models that efficiently deal with those longer contexts is of paramount importance. In our business case, which is to create summaries of conversation threads, much as you might see in Slack or an email chain, the models need to be able to extract key information from those threads while still being able to accept a large context window to capture the entire conversation history.We identified that it is far more valuable to conduct abstractive summaries, or summaries that identify important sections in the text and generate highlights,  rather than extractive ones, which pick a subset of sentences and add them together for our use cases since the final interface will be natural language. We want the summary results not to need to be interpreted from often incoherent text snippets produced by extractive summaries. \n",
    "\n",
    "For more on summarization as a use-case, [see our blog post here.](https://blog.mozilla.ai/on-model-selection-for-text-summarization/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e0905",
   "metadata": {},
   "source": [
    "## Ground Truth for Models\n",
    "\n",
    "In order to generate ground truth, we need to generate some baseline summaries. We'll do this by performing inference against existing models that are trained for summarization. Let's take a look at the data we'll be using first. [Generating GT](https://thunderbird.topicbox.com/groups/addons/T18e84db141355abd-M4cca8e3f9e4fee9ae14b9dbb/self-hosted-version-of-extension-is-incorrectly-appearing-in-atn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What are LLMS? \n",
    "\n",
    "Large language models work by "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1493b-ecbd-4b2c-a13a-58365cc15023",
   "metadata": {},
   "source": [
    "## Generating Data for Ground Truth Evaluation\n",
    "\n",
    "In order to generate a ground truth summary for our data, we first need an input dataset. In this case we use threads from the [Thunderbird public mailing list.](https://thunderbird.topicbox.com/latest)  To generate the ground truth and then later evaluate the model, we need at least 100 samples to start with, where a sample is a single email or single email conversation.\n",
    "\n",
    "Our selection criteria: \n",
    "\n",
    "+ Collect 100 samples of email thread conversations, as recent as possible and fairly complete so they can be evaluated\n",
    "+ Clean them of email formatting such as `>`\n",
    "+ One consideration here will be that BART, the baseline model we're using, accepts 1024 token context window as input, i.e.  we have to have input email threads that are ~ approximately 1000 words, so keeping on the conservative side\n",
    "\n",
    "Once we've collected them, we'd like to take a look at the data before we generate summaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36323a9e-aec4-402f-81c0-164f4f890723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T17:59:45.160392Z",
     "start_time": "2024-07-17T17:59:45.157516Z"
    }
   },
   "outputs": [],
   "source": [
    "# show information about the Thunderbird dataset\n",
    "dataset_id = \"db7ff8c2-a255-4d75-915d-77ba73affc53\"\n",
    "r = ld.dataset_info(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab1a6c-30bc-421d-908d-20268cdefb98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:00:10.371832Z",
     "start_time": "2024-07-17T18:00:10.354800Z"
    }
   },
   "outputs": [],
   "source": [
    "# download the dataset into a pandas dataframe\n",
    "df = ld.dataset_download(dataset_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb735b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "def preprocess_text(text:str):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(f\"[{re.escape(punctuation)}]\", \"\", text)  # Remove punctuation\n",
    "    text = \" \".join(text.split())  # Remove extra spaces, tabs, and new lines\n",
    "    text = re.sub(r\"\\b[0-9]+\\b\\s*\", \"\", text)\n",
    "    return text\n",
    "\n",
    "df[\"examples\"].map(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ddccc-33ab-4204-967a-d266b8ff051e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:00:25.102809Z",
     "start_time": "2024-07-17T18:00:25.098826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Examine a single sample \n",
    "# we define the data with examples\n",
    "df['examples'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a4fa9-ce82-43ec-a2b1-0fc984b23cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:00:28.965534Z",
     "start_time": "2024-07-17T18:00:28.962726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a function to do some simple character counts for model input\n",
    "df['char_count'] = df['examples'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1336138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9694e3-d4d3-46b6-9023-4744f1ab73e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:00:31.627488Z",
     "start_time": "2024-07-17T18:00:31.620802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show statistics about characters count\n",
    "df['char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28c016-5aae-47f2-a18e-e470cae8ef4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:00:33.594470Z",
     "start_time": "2024-07-17T18:00:33.477793Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(df['char_count'], bins=30)\n",
    "ax.set_xlabel('Character Count')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "stats = df['char_count'].describe().apply(lambda x: f\"{x:.0f}\")\n",
    "\n",
    "# Add text boxes for statistics\n",
    "plt.text(1.05, 0.95, stats.to_string(), \n",
    "         transform=ax.transAxes, verticalalignment='top')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(right=0.75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "what is ground truth? how do we vibe-compare it between models? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffe26e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"The user has released a beta version 7.0b1 of their extension, Clippings for Thunderbird, and made it available for testing separately while keeping the current stable release 6.3.5 for regular users. However, the beta version was mistakenly listed on the Add-ons for Thunderbird public listing. The user was advised to open an issue on the addons-server GitHub repository, as self-hosted add-ons should not be submitted to ATN, especially if they do not have an update_url entry in their manifest. The best practices for self-hosting add-ons include removing the beta version from ATN, creating a dedicated branch or repo for update information, hosting XPI files as \\\"beta\\\" assets in a GitHub release or directly in the repo, and ensuring the manifest points to the correct update.json file. The user has successfully followed these steps and removed the beta version from ATN.\"\n",
      "}\n",
      "Response from Mistral The user has released a beta version 7.0b1 of their extension, Clippings for Thunderbird, and made it available for testing separately while keeping the current stable release 6.3.5 for regular users. However, the beta version was mistakenly listed on the Add-ons for Thunderbird public listing. The user was advised to open an issue on the addons-server GitHub repository, as self-hosted add-ons should not be submitted to ATN, especially if they do not have an update_url entry in their manifest. The best practices for self-hosting add-ons include removing the beta version from ATN, creating a dedicated branch or repo for update information, hosting XPI files as \"beta\" assets in a GitHub release or directly in the repo, and ensuring the manifest points to the correct update.json file. The user has successfully followed these steps and removed the beta version from ATN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Thunderbird is preparing its next major release, Thunderbird 128 ESR. Developers of add-ons should check their compatibility with this new version as it is currently being distributed through the beta release channel. The changes required for compatibility mainly affect Experiment add-ons. WebExtensions generally do not need updates, but new permission 'messagesUpdate' has been introduced, and the 'browser.messages.update()' function will stop working if the new permission is not requested. Another significant change is the official support for Manifest Version 3 in Thunderbird 128. The add-ons team has also updated the API documentation on webextension-api.thunderbird.net, which now includes both Thunderbird and Firefox WebExtension APIs. For any assistance, developers can reach out to the Thunderbird community.\"\n",
      "}\n",
      "Response from Mistral Thunderbird is preparing its next major release, Thunderbird 128 ESR. Developers of add-ons should check their compatibility with this new version as it is currently being distributed through the beta release channel. The changes required for compatibility mainly affect Experiment add-ons. WebExtensions generally do not need updates, but new permission 'messagesUpdate' has been introduced, and the 'browser.messages.update()' function will stop working if the new permission is not requested. Another significant change is the official support for Manifest Version 3 in Thunderbird 128. The add-ons team has also updated the API documentation on webextension-api.thunderbird.net, which now includes both Thunderbird and Firefox WebExtension APIs. For any assistance, developers can reach out to the Thunderbird community.\n",
      "{\n",
      "  \"text\": \"The sender is discussing an extension that displays thumbnails of PDF files within the message pane, making it faster to preview them instead of opening them directly. Previously, the extension used PDF.js, but the sender is questioning if this is still necessary. The sender advises against depending on files shipped with Thunderbird, as they can be moved or renamed, leading to compatibility issues with the add-on. Instead, they suggest shipping your own version of the necessary files to ensure the add-on always uses a consistent version and stays compatible with potential API changes in Thunderbird updates. The sender is signed off as John.\"\n",
      "}\n",
      "Response from Mistral The sender is discussing an extension that displays thumbnails of PDF files within the message pane, making it faster to preview them instead of opening them directly. Previously, the extension used PDF.js, but the sender is questioning if this is still necessary. The sender advises against depending on files shipped with Thunderbird, as they can be moved or renamed, leading to compatibility issues with the add-on. Instead, they suggest shipping your own version of the necessary files to ensure the add-on always uses a consistent version and stays compatible with potential API changes in Thunderbird updates. The sender is signed off as John.\n",
      "{\n",
      "  \"text\": \"Gerson is developing an addon for Thunderbird to open Zulip team chats in a new tab. He encountered an issue where left-clicking on external links or PDF files within Zulip chats breaks the Thunderbird internal browser, but right-clicking and selecting \\\"open in browser\\\" works fine. He noticed that the broken links have a target=\\\"_blank\\\" attribute.\\n\\nJohn suggested using a content script to change the behavior of link clicks within the Thunderbird content tab. This involves adding a content_scripts section to the extension's manifest and defining a global clickhandler that sends a message to the background script with the link href when clicked.\\n\\nGerson tested this suggestion and found that not all broken links have the target=\\\"_blank\\\" attribute. He identified that links starting with \\\"/user\\\\_uploads\\\" within Zulip are the ones breaking, and they need to have the Zulip prefix added to them. He split the suggested code into a background script and a content-script script to handle this case specifically. He plans to test this for a few days and look out for other issues.\"\n",
      "}\n",
      "Response from Mistral Gerson is developing an addon for Thunderbird to open Zulip team chats in a new tab. He encountered an issue where left-clicking on external links or PDF files within Zulip chats breaks the Thunderbird internal browser, but right-clicking and selecting \"open in browser\" works fine. He noticed that the broken links have a target=\"_blank\" attribute.\n",
      "\n",
      "John suggested using a content script to change the behavior of link clicks within the Thunderbird content tab. This involves adding a content_scripts section to the extension's manifest and defining a global clickhandler that sends a message to the background script with the link href when clicked.\n",
      "\n",
      "Gerson tested this suggestion and found that not all broken links have the target=\"_blank\" attribute. He identified that links starting with \"/user\\_uploads\" within Zulip are the ones breaking, and they need to have the Zulip prefix added to them. He split the suggested code into a background script and a content-script script to handle this case specifically. He plans to test this for a few days and look out for other issues.\n",
      "{\n",
      "  \"text\": \"The user Mark is attempting to replicate the behavior in Thunderbird's main window, message view, and compose windows where the OS-supplied titlebar is hidden and window movement is done using the toolbar, as achieved by setting 'mail.tabs.drawInTitlebar=true' in the Config Editor. However, they are unable to achieve this behavior in their custom extension. They've found that adding the 'chromemargin' attribute to the '<html>' tag in Thunderbird's HTML/XUL triggers this behavior, but it doesn't work for their extension's windows. They have attempted to find event listeners or other values to replicate this behavior in their extension without success. They've looked at Thunderbird's source code but feel they don't have enough expertise to figure it out. They're reaching out for help or guidance from someone with the necessary knowledge. A potential solution was suggested in a MozillaZine forums post, but the user didn't provide more details.\"\n",
      "}\n",
      "Response from Mistral The user Mark is attempting to replicate the behavior in Thunderbird's main window, message view, and compose windows where the OS-supplied titlebar is hidden and window movement is done using the toolbar, as achieved by setting 'mail.tabs.drawInTitlebar=true' in the Config Editor. However, they are unable to achieve this behavior in their custom extension. They've found that adding the 'chromemargin' attribute to the '<html>' tag in Thunderbird's HTML/XUL triggers this behavior, but it doesn't work for their extension's windows. They have attempted to find event listeners or other values to replicate this behavior in their extension without success. They've looked at Thunderbird's source code but feel they don't have enough expertise to figure it out. They're reaching out for help or guidance from someone with the necessary knowledge. A potential solution was suggested in a MozillaZine forums post, but the user didn't provide more details.\n",
      "{\n",
      "  \"text\": \"The user is experiencing an issue with a Chrome extension that uses a third-party script with a web worker option for performance improvements. However, a Content Security Policy (CSP) exception is being generated, preventing the loading of the resource. The user suspects that a meta tag needs to be added to the popup page but is unsure of the exact content.\\n\\nThe user is working on the 'extract-em' extension, which switches from JSZip to zip.js for handling larger output files. Zip.js offers Web Workers, but their use incurs an error in the 'getWebWorker' method of the zip.js file. The user has provided a link to the GitHub repository and a screenshot of the error message for further analysis.\\n\\nPersonally, I would suggest reaching out to the developer of zip.js for a solution, as they may have a better understanding of how to work around the CSP restriction in their specific scenario. Also, check if there are any options to configure or bypass the CSP in the specific extension or web page context.\"\n",
      "}\n",
      "Response from Mistral The user is experiencing an issue with a Chrome extension that uses a third-party script with a web worker option for performance improvements. However, a Content Security Policy (CSP) exception is being generated, preventing the loading of the resource. The user suspects that a meta tag needs to be added to the popup page but is unsure of the exact content.\n",
      "\n",
      "The user is working on the 'extract-em' extension, which switches from JSZip to zip.js for handling larger output files. Zip.js offers Web Workers, but their use incurs an error in the 'getWebWorker' method of the zip.js file. The user has provided a link to the GitHub repository and a screenshot of the error message for further analysis.\n",
      "\n",
      "Personally, I would suggest reaching out to the developer of zip.js for a solution, as they may have a better understanding of how to work around the CSP restriction in their specific scenario. Also, check if there are any options to configure or bypass the CSP in the specific extension or web page context.\n",
      "{\n",
      "  \"text\": \"It seems like you're having issues with a content script that you're writing. Here are the main challenges you're facing:\\n\\n1. You're unable to see the console logs from your content script in the debug console when using the inspect button. However, messages from the background script and a popup.js registered via the manifest are being displayed without issues.\\n\\n2. When you try to send a message from the background script to your content script using the `onMessage` listener, you're getting an \\\"Error: Could not establish connection. Receiving end does not exist\\\" error. Despite this, the script seems to be running when you select the message, as you can see the red-boxed text from the message-content-script example.\\n\\nYou've also raised some questions about the behavior of content scripts:\\n\\n- Shouldn't the script wake up and react to a message from the background, even if it's normally sleeping/inactive?\\n- Is it possible for a content script to listen to messages from the background?\\n- Or should you be injecting the code freshly when you want to listen to messages from the background?\\n\\nTo address these issues,\"\n",
      "}\n",
      "Response from Mistral It seems like you're having issues with a content script that you're writing. Here are the main challenges you're facing:\n",
      "\n",
      "1. You're unable to see the console logs from your content script in the debug console when using the inspect button. However, messages from the background script and a popup.js registered via the manifest are being displayed without issues.\n",
      "\n",
      "2. When you try to send a message from the background script to your content script using the `onMessage` listener, you're getting an \"Error: Could not establish connection. Receiving end does not exist\" error. Despite this, the script seems to be running when you select the message, as you can see the red-boxed text from the message-content-script example.\n",
      "\n",
      "You've also raised some questions about the behavior of content scripts:\n",
      "\n",
      "- Shouldn't the script wake up and react to a message from the background, even if it's normally sleeping/inactive?\n",
      "- Is it possible for a content script to listen to messages from the background?\n",
      "- Or should you be injecting the code freshly when you want to listen to messages from the background?\n",
      "\n",
      "To address these issues,\n",
      "{\n",
      "  \"text\": \"Wes is a long-time Thunderbird user and a programmer who is interested in developing a basic CRM add-on for Thunderbird. The add-on would include two main features:\\n\\n1. A new button on received emails that allows users to create a new folder and set up a mail filter based on the domain name or other entered text. If a matching config already exists for the received email, the button would send the email to the existing folder instead.\\n2. A schedule response feature that would prompt the user to enter a date and title/description. Once the date and time arrive, Thunderbird would pop up the text entered as a reminder to respond to the client. The scheduled items could appear where the current 'task' list is when using the calendar in Thunderbird.\\n\\nJohn, a Thunderbird developer, responds by confirming that some CRM add-ons have passed through review and that Wes can have a button in the message header area, create folders, prompt the user for configuration data, and react to incoming email. However, there is no way to create a \\\"real\\\" email filter as of now, but a reminder functionality can be implemented or used with an existing add-on like\"\n",
      "}\n",
      "Response from Mistral Wes is a long-time Thunderbird user and a programmer who is interested in developing a basic CRM add-on for Thunderbird. The add-on would include two main features:\n",
      "\n",
      "1. A new button on received emails that allows users to create a new folder and set up a mail filter based on the domain name or other entered text. If a matching config already exists for the received email, the button would send the email to the existing folder instead.\n",
      "2. A schedule response feature that would prompt the user to enter a date and title/description. Once the date and time arrive, Thunderbird would pop up the text entered as a reminder to respond to the client. The scheduled items could appear where the current 'task' list is when using the calendar in Thunderbird.\n",
      "\n",
      "John, a Thunderbird developer, responds by confirming that some CRM add-ons have passed through review and that Wes can have a button in the message header area, create folders, prompt the user for configuration data, and react to incoming email. However, there is no way to create a \"real\" email filter as of now, but a reminder functionality can be implemented or used with an existing add-on like\n",
      "{\n",
      "  \"text\": \"The Thunderbird Council election is approaching, and to vote or run as a candidate, you must be on the electoral roll. Contributors who have given 10 hours or more annually to the Thunderbird project in the past year are eligible. This contribution can take many forms, such as triaging bugs, fixing code, providing support, localizing Thunderbird, testing, writing add-ons, contributing to tb-planning, or doing public relations. Mozilla employees working on Thunderbird are also eligible. The electoral roll is available on GitHub, and new candidates should ensure they meet the criteria and notify the Council if they no longer contribute at the required level or don't wish to participate. The election process will follow the same path as previous years, and the election will be overseen by neutral third parties.\"\n",
      "}\n",
      "Response from Mistral The Thunderbird Council election is approaching, and to vote or run as a candidate, you must be on the electoral roll. Contributors who have given 10 hours or more annually to the Thunderbird project in the past year are eligible. This contribution can take many forms, such as triaging bugs, fixing code, providing support, localizing Thunderbird, testing, writing add-ons, contributing to tb-planning, or doing public relations. Mozilla employees working on Thunderbird are also eligible. The electoral roll is available on GitHub, and new candidates should ensure they meet the criteria and notify the Council if they no longer contribute at the required level or don't wish to participate. The election process will follow the same path as previous years, and the election will be overseen by neutral third parties.\n",
      "{\n",
      "  \"text\": \"The provided text appears to be a bug report for Thunderbird, an email client developed by Mozilla. The report includes both new bugs and resolved bugs reported within the last 24 hours.\\n\\nNew bugs:\\n1. ID 1907113: This is a defect with many C-C TB xpcshell tests failing, with an assertion error at mozilla/netwerk/base/idna_glue/src/lib.rs:66. The bug is currently reopened.\\n2. ID 1907115: Two Factor OAuth (for text and email) is not working with Office365. This is a new bug report.\\n3. ID 1907245: An access violation exception (ExceptionCode: c0000005) is occurring, which is an unconfirmed defect.\\n4. ID 1907248-1907249: These are two unconfirmed defects related to sending plain text format, rendering drop-down items, and allowing calendar invitations to be encrypted.\\n\\nResolved bugs:\\n1.\"\n",
      "}\n",
      "Response from Mistral The provided text appears to be a bug report for Thunderbird, an email client developed by Mozilla. The report includes both new bugs and resolved bugs reported within the last 24 hours.\n",
      "\n",
      "New bugs:\n",
      "1. ID 1907113: This is a defect with many C-C TB xpcshell tests failing, with an assertion error at mozilla/netwerk/base/idna_glue/src/lib.rs:66. The bug is currently reopened.\n",
      "2. ID 1907115: Two Factor OAuth (for text and email) is not working with Office365. This is a new bug report.\n",
      "3. ID 1907245: An access violation exception (ExceptionCode: c0000005) is occurring, which is an unconfirmed defect.\n",
      "4. ID 1907248-1907249: These are two unconfirmed defects related to sending plain text format, rendering drop-down items, and allowing calendar invitations to be encrypted.\n",
      "\n",
      "Resolved bugs:\n",
      "1.\n"
     ]
    }
   ],
   "source": [
    "## Perform Ground Truth Generation with Mistral \n",
    "\n",
    "responses = []\n",
    "\n",
    "for sample in df['examples'][0:10]:\n",
    "    response = ld.get_mistral_ground_truth(sample)\n",
    "    print(f\"Mistral:\", response)\n",
    "    responses.append((sample, response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're adding these results \n",
    "mistral_results_df = pd.DataFrame(responses, columns=['Original', 'Response'])\n",
    "\n",
    "mistral_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "ways to run LLMs: API access, running on cluster, and running locally \n",
    "what is Ray? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "Lumigator and LM-Buddy, how they work together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at all available deploys\n",
    "ld.get_deployments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f8a00b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://lumigator.mzai.dev/api/v1/ground-truth/deployments/bbdd0114-7e43-4222-86c6-541dab987586\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "500 Server Error: Internal Server Error for url: https://lumigator.mzai.dev/api/v1/ground-truth/deployments/bbdd0114-7e43-4222-86c6-541dab987586",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m deployment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbdd0114-7e43-4222-86c6-541dab987586\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m string \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bart_ground_truth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[1;32m      9\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend((string, response))\n",
      "File \u001b[0;32m~/lumigator-demo/lumigator_demo.py:272\u001b[0m, in \u001b[0;36mget_bart_ground_truth\u001b[0;34m(deployment_id, prompt)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete_deployment\u001b[39m(deployment_id:UUID) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m requests\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[1;32m    271\u001b[0m     response \u001b[38;5;241m=\u001b[39m make_request(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/ground-truth/deployments/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDELETE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/lumigator-demo/lumigator_demo.py:70\u001b[0m, in \u001b[0;36mmake_request\u001b[0;34m(url, method, params, data, files, headers, json_, timeout, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m     59\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m     60\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,  \u001b[38;5;66;03m# noqa: B026\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     )\n\u001b[0;32m---> 70\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson\u001b[38;5;241m.\u001b[39mdumps(response\u001b[38;5;241m.\u001b[39mjson(),\u001b[38;5;250m \u001b[39mindent\u001b[38;5;250m \u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/envs/lumigator/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://lumigator.mzai.dev/api/v1/ground-truth/deployments/bbdd0114-7e43-4222-86c6-541dab987586"
     ]
    }
   ],
   "source": [
    "## Perform Ground Truth Generation with BART\n",
    "\n",
    "# PUT DEPLOYMENT ID HERE \n",
    "deployment_id = \"510aff69-8634-43b8-8153-386957b03778\"\n",
    "\n",
    "for string in df['examples'][0:1]:\n",
    "    response = ld.get_bart_ground_truth(deployment_id,string)\n",
    "    print(response)\n",
    "    responses.append((string, response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e914253-e217-42f8-85a2-59f32daf6779",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd66191-c874-4303-bd26-ef93388a124f",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "The following dataset is already in the format that we need as input: \n",
    "- one field called `examples` containing the text to summarize\n",
    "- one field called `ground_truth` containing the summaries to the models' outputs against\n",
    "\n",
    "Note that you can load many different types of file formats in a similar way (see https://huggingface.co/docs/datasets/loading#local-and-remote-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb40cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "\n",
    "huggingface datasets versus csv\n",
    "and lm-buddy prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0682d-0dd6-49b1-a4dc-8581760b1a59",
   "metadata": {},
   "source": [
    "## Dataset Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbcb60-5940-41e5-873f-b346f8bad5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"thunderbird.csv\"\n",
    "dataset_id = \"f5d54efa-247d-4910-9393-f6003da9fb68\" # thunderbird pre-saved dataset HuggingFace\n",
    "\n",
    "r = ld.dataset_info(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2876b7f8-e645-4791-aa27-351e3296e2de",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "What you see below are different lists of models we have already tested for the summarization task.\n",
    "The `models` variable at the end provides you with a selection, but you can choose any combination of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fcdf76-c9ad-4459-b0c3-49098286ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_models = [\n",
    "    'hf://facebook/bart-large-cnn',\n",
    "    'hf://mikeadimech/longformer-qmsum-meeting-summarization', \n",
    "    'hf://mrm8488/t5-base-finetuned-summarize-news',\n",
    "    'hf://Falconsai/text_summarization',\n",
    "]\n",
    "\n",
    "dec_models = [\n",
    "    'mistral://open-mistral-7b',\n",
    "]\n",
    "\n",
    "gpts = [\n",
    "    \"oai://gpt-4o-mini\",\n",
    "    \"oai://gpt-4-turbo\",\n",
    "    \"oai://gpt-3.5-turbo-0125\"  \n",
    "]\n",
    "\n",
    "# TODO: add llamafile\n",
    "\n",
    "models = [\n",
    "    enc_dec_models[0], # bart-large-cnn\n",
    "    dec_models[0], # Mistral-7B-Instruct-v0.3\n",
    "    gpts[0] # gpt-4o-mini\n",
    "]\n",
    "\n",
    "# show selected models\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f83baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "Introduce metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74658955-4a41-4be1-b29d-8efa734bed9d",
   "metadata": {},
   "source": [
    "## Run Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73f6a1-7be9-43a7-8304-4cb6a408318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the following to 0 to use all samples in the dataset\n",
    "max_samples = 10\n",
    "\n",
    "responses = []\n",
    "for model in models:\n",
    "    descr = f\"Testing {model} summarization model on {dataset_name}\"\n",
    "    responses.append(ld.experiments_submit(model, team_name, descr, dataset_id, max_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc890c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "Discuss Ray dashboard/show dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f787190-4581-4c26-beca-0260303a68bd",
   "metadata": {},
   "source": [
    "### Track evaluation jobs\n",
    "\n",
    "Run the following to track your evaluation jobs.\n",
    "\n",
    "- *NOTE*: you won't be able to run other cells while this one is running. However, you can interrupt it whenever you want by clicking on the \"stop\" button above and run it at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858bcea-6fcb-4441-b56e-5d89502f10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ids = [ld.get_resource_id(r) for r in responses]\n",
    "\n",
    "wip = ld.show_experiment_statuses(job_ids)\n",
    "while wip == True:\n",
    "    time.sleep(5)\n",
    "    clear_output()\n",
    "    wip=ld.show_experiment_statuses(job_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8cbf3-e44f-4f1e-b520-3f6fac147fca",
   "metadata": {},
   "source": [
    "## Show evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8709b8-59ba-4a9c-81bd-59b2fc612f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after the jobs complete, gather evaluation results\n",
    "eval_results = []\n",
    "for job_id in job_ids:\n",
    "    eval_results.append(ld.experiments_result_download(job_id))\n",
    "\n",
    "# convert results into a pandas dataframe\n",
    "eval_table = ld.eval_results_to_table(models, eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf5e90-7fa2-4a7d-98bf-2ff5d736c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbdaec-a1e9-4731-bfdd-b471e6a0fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b450ce",
   "metadata": {},
   "source": [
    "## Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "add eval discussion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
